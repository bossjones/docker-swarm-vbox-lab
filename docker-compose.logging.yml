version: '3'

# source: https://github.com/botleg/swarm-logging/blob/master/docker-stack.yml

services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:5.3.2
    environment:
      ES_JAVA_OPTS: '-Xms256m -Xmx256m'
      # NOTE: https://www.elastic.co/products/x-pack
      # Security for elasticsearch
      # For this demo, we will disable the X-Pack.
      xpack.security.enabled: 'false'
      xpack.monitoring.enabled: 'false'
      xpack.graph.enabled: 'false'
      xpack.watcher.enabled: 'false'
    volumes:
      - esdata:/usr/share/elasticsearch/data
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.hostname == node-01

  logstash:
    image: docker.elastic.co/logstash/logstash:5.3.2
    volumes:
      - ./logstash/logstash.conf:/usr/share/logstash/pipeline/logstash.conf
    depends_on:
      - elasticsearch
    deploy:
      replicas: 1

  logspout:
    image: bekt/logspout-logstash
    environment:
      ROUTE_URIS: 'logstash://logstash:5000'
    ports:
      - '8000:80'
    # We also need to create a volume for the Docker socket,
    # /var/run/docker.sock.
    # This lets the container to attach to the docker daemon
    # in the host and collect all the logs.
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      - logstash
    deploy:
      mode: global
      restart_policy:
        condition: on-failure
        delay: 30s

  kibana:
    image: docker.elastic.co/kibana/kibana:5.3.2
    # The router mesh feature will then let us access
    # kibana from port 8088 of any host in the swarm.
    ports:
      - '8088:5601'
    depends_on:
      - elasticsearch
    environment:
      ELASTICSEARCH_URL: 'http://elasticsearch:9200'
      XPACK_SECURITY_ENABLED: 'false'
      XPACK_MONITORING_ENABLED: 'false'
    deploy:
      replicas: 1

volumes:
  esdata:
    driver: local
